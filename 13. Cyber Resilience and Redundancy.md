Cyber Resilience
Entity's ability to continuously deliver the intended outcome despite adverse cyber events.

Redundancy
involves having additional systems, equipment, or processes to ensure continued functionality if the primary once fails.
### High Availability
The ability of a service to be continuously available by minimizing the downtime to the lowest amount possible.

To achieve high availability, our systems should be designed using load balancing or clustering, have redundancy built into the system, and if we are operating in a cloud-based environment, we should also consider using a multi-cloud environment to achieve an operational environment that can withstand multiple points of failure before our service become unavailable.
##### Uptime
The number of minutes or hours that the system remains online over a given period, and this uptime is usually expressed as a percentage.

```
Five 9s availability - System uptime is 99.999%, allowing about 5.26 minutes of downtime per year
 Six 9s availability - System uptime is 99.9999%, allowing about 31.5 seconds of downtime per year
```

How to achieve High Availability:
1. Load Balancing
2. Clustering
3. Redundancy
4. Multi-Cloud Architecture

Explanations:
1. Load Balancing
   The process of distributing workloads across multiple computing resources to optimize the resources use, maximize their throughput, minimize their response time, and prevent the overloading of any single resources.
   
2. Clustering
   The use of multiple computers, multiple storage devices, and redundant network connections that all work together as a single system to provide high levels of availability, reliability, and scalability.
   
   Load balancing helps manage excess traffic by distributing incoming requests across multiple servers, preventing overload and ensuring smooth performance. Clustering, on the other hand, provides redundancy - if one server fails, another can immediately take over, maintaining service continuity. Both techniques can be combined within the same architecture to build a highly robust and resilient system capable of maintaining higher levels of availability.

3. Redundancy
   The duplication of critical components or functions of a system with the intention of increasing the reliability of the system. 
   To create a highly available infrastructure, redundancy has to be built into your designs by installing or adding multiple power supplies, network connections, servers, software services and service providers.
   
4. Multi-Cloud Architecture
   Utilize multi-cloud systems to distribute data, applications, and services across several different cloud-based environments.
   Using a multi-cloud system also provides some additional flexibility for scaling operations and for optimizing costs.
### Data Redundancy
Now, one of the most effective ways to create data redundancy is to use a RAID.

RAID (Redundancy Array of Independent Disks):
Combines multiple physical storage devices into a single logical storage device that is recognized by your operating system.
There are many types of RAID configurations, but the most commonly used and widely adopted ones are the following:
1. RAID 0 (Striping)
   Provides data striping across multiple disks to increase performance, RAID 0 is for performance without fault tolerance concerns.
   RAID 0 is the only kind of RAID that does not provide you with any kind of data redundancy, but instead, it provides us with faster read and write speeds.
   Example:
   If you store a 100 MB file on a 2-disk RAID 0 array:
   50 MB goes to Disk 1
   50 MB goes to Disk 2
   This results in faster performance, but zero fault tolerance.
   Use case:
   High-performance tasks where data loss is acceptable (e.g., gaming PCs, temporary data processing).
   
2. RAID 1 (Mirroring)
   Mirrors data for redundancy across two drives or SSDs, to provide the least amount of downtime.
   Example:
   If you have a 500 GB drive mirrored in RAID 1:
   Disk 1 = 500 GB of data
   Disk 2 = the same 500 GB (identical copy)
   Use case:
   Critical systems like financial databases or authentication servers.
   
3. RAID 5 (Striping with parity)
   Stripes data with parity, using at least three storage devices, and can survive one disk failure.
   In RAID 5, parity is extra information stored across the disks that helps rebuild data if one drive fails. Because of this, RAID 5 allows hot swapping, meaning you can remove and replace a failed drive while the system is still running. After inserting a new disk, the RAID automatically uses the parity data to recover and rebuild everything that was lost, keeping the system online with minimal disruption.
   Example:
   3 Drives: A, B, C
   Data blocks written as stripes: D1, D2
   Parity block P helps rebuild any lost data if one drive dies.
   Use case:
   Enterprise servers, NAS devices — good balance of speed, storage, and protection.
   
4. RAID 6 (Striping with double parity)
   Uses data striping across multiple devices with two pieces of parity data, and can survive two drive failures.
   Example:
   4 Drives: A, B, C, D
   Stores data + 2 parity blocks across all drives
   Even if Disk B and Disk D fail, data is recoverable.
   Use case:
   Large servers needing maximum protection (e.g., high-availability storage systems).
   
5. RAID 10 (Striped array of mirrored arrays)
   Combines RAID 0 and RAID 0, featuring mirrored arrays in striped setup, data is mirrored first, then striped across pairs and needs minimum 4 drives.
   Example:
   4 Drives in RAID 10:
   Disk 1 ↔ Disk 2 (mirrored pair)
   Disk 3 ↔ Disk 4 (mirrored pair)
   These pairs are then striped for performance.
   Use case:
   Mission-critical databases, high-performance servers.
#### Classification of RAID
1. Failure-Resistant RAID:
   Failure-resistant RAID uses **redundant storage** to help systems withstand hardware malfunctions without losing data. By keeping duplicate copies or combining drives cleverly, these RAID levels ensure data remains available even if a disk fails.  
   Examples: RAID 1 and RAID 10

2. Fault-Tolerant RAID:
   Fault-tolerant RAID levels can continue operating even if one or more disks fail. They use techniques like mirroring or parity to rebuild data.
   Examples: RAID 1, RAID 5, RAID 6, RAID 10

3. Disaster-Tolerant RAID:
   These RAID setups protect against large-scale failures, such as an entire site losing its storage due to fire, flood, or power outage. They often involve RAID across multiple locations or data centers.
   Example: RAID 1 over distance (synchronous mirroring between two sites)
### Capacity Planning
Crucial strategic planning to meet future demands cost-effectively.
When it comes to conducting capacity planning, you need to consider four main aspects:
- People:
  Involves analyzing current skills and forecasting future needs for hiring or training.
- Technology:
  Involves assessing current resources, utilization, and anticipating future technological needs.
- Infrastructure:
  Involves considering physical space and utilities to support organizational operations.
- Processes:
  Aims to optimize business processes to handle demand fluctuations.

Capacity planning ensures a system can handle future demand by preparing people, technology, infrastructure, and processes in advance. For example, if a bank expects a surge in mobile app usage after launching a new feature, it may train extra support staff, upgrade servers and enable auto-scaling, add more storage and network capacity, and automate slow manual workflows to prevent bottlenecks. By planning across all these areas in advance, the bank ensures smooth performance, avoids downtime, and delivers a seamless user experience even during peak load.
### Powering Data Centers
Now, when it comes to power, there are five key terms that describe the current state of the power being received by our systems:
1. Surge: A small and unexpected increase in the amount of voltage being supplied.
2. Spike: A very short, sudden burst of voltage, usually caused by events like a short circuit, tripped breaker, power outage, or lightning strike.
3. Sag: A small and unexpected decrease in the amount of voltage being provided.
4. Under voltage (Brownout): A condition where voltage is reduced to lower levels and remains that way for a longer period of time.
5. Power Loss (Blackout): A situation where there is a complete loss of power for a given period of time.

Solutions:
1. Line Conditioners:
   Line conditioners are devices used to smooth out minor fluctuations in the power supplied to a system. They help protect equipment from issues like surges (small voltage increases), sags (small voltage drops), and under voltage events. Their job is to ensure the connected systems receive stable, consistent power.

2. Uninterruptible Power Supply (UPS):
   A UPS provides emergency backup power when the main power source fails. Besides offering battery power during outages, a UPS also performs line conditioning, meaning it stabilizes voltage and filters out minor power fluctuations. This allows systems to keep running smoothly - even during a complete power failure - until proper shutdown or generator switchover can occur.

3. Generator:
   A generator is a machine that converts mechanical energy into electrical energy using electromagnetic induction. When activated during a power outage, it can supply long-term backup power to keep essential systems and infrastructure running.

4. Power Distribution Center (PDC):
   A PDC acts as the central hub for electrical power within a data center. It receives incoming power and distributes it safely across racks, servers, storage systems, and other equipment, ensuring stable and organized power flow.

Most large data centers use rack-mounted UPS units to provide both line conditioning and battery backup, guaranteeing stable and uninterrupted power to critical systems even during electrical disturbances or outages.
### Data Backups
Data backup is the process of creating duplicate copies of digital information to protect it from loss, corruption, or unavailability. The golden rule is simple: never keep all your data in one place. If all your information stays on a single device or server, you risk losing everything due to accidental deletion, hardware failure, or unexpected disasters. That’s why creating backups - and in the case of critical data, multiple backups - is considered a best practice.

1. Onsite vs Offsite Backup:
   Onsite backup means your backup data is stored physically within your own environment—such as in your office or data center. For example, if you back up your laptop to an external hard drive and keep that drive in your desk drawer, that’s an onsite backup. It’s convenient and allows quick restoration, but it can still be lost if a fire, flood, or major outage affects the location.
   Offsite backup involves storing duplicate copies of your data at a geographically separate location. This protects your information from physical disasters and ensures business continuity. Offsite backups might be stored in another branch office, a secure storage facility, or a cloud-based service.

2. Backup Frequency:
   Backup frequency refers to how often an organization creates backups, and it directly depends on how much data the company is willing to lose if something goes wrong. For example, if a business can afford to lose only a few minutes of data, it needs very frequent backups or real-time replication. But if losing a few hours of data is acceptable, daily backups may be enough. In short, the more critical the data, the more frequently backups should be taken to minimize potential loss.

3. Encryption on Backups:
   Encryption is a fundamental safeguard that protects backup data from unauthorized access. Even if someone steals or gains access to the backup files, they cannot read the data without the correct decryption key. Encryption ensures confidentiality both when the data is stored (data at rest) and when it is being transferred to a backup location (data in transit).

4. Snapshots:
   Snapshots are point-in-time copies of data that capture a consistent and frozen state. Unlike full backups, snapshots don’t copy everything every time - they only track changes made since the last snapshot.
   This makes them fast, efficient, and especially useful for systems like databases or file servers where maintaining a consistent state is critical. If something goes wrong, snapshots allow you to roll the system back to an exact moment in time.

5. Recovery:
   Recovery is the process of restoring data after a loss, corruption, or system failure. It’s the ultimate purpose of having backups in the first place. Recovery may involve selecting the correct backup or snapshot, restoring it to the system, validating the data, and ensuring everything works as expected. A strong recovery plan ensures the organization can quickly regain access to critical information with minimal disruption.

6. Replication:
   Replication is the process of making real-time or near-real-time copies of data to another system or location.
   This is often used in high-availability environments, where the goal is to ensure that data is always accessible—even if the primary system fails. Replication reduces downtime and improves resilience.

7. Journaling
   Journaling means keeping a detailed log of every change made to data over time. Instead of backing up full copies, a journal records each modification, addition, or deletion. This allows precise reconstruction of data—like rolling a database back to the exact state it was in before an issue occurred. It’s commonly used in file systems and databases to maintain integrity.
### Continuity of Operations Plan
Ensure an organization's ability to recover from disruptive events or disasters.
- Business Continuity Plan (Incident):
  Addresses responses to disruptive events
  Example:
  A company’s primary application server crashes due to a software bug. The Business Continuity Plan kicks in: employees switch to a backup server, customer support uses manual logging temporarily, and the IT team follows a predefined checklist to minimize downtime.
- Disaster Recovery Plan (Disaster):
  Considered as a subset of BC plan, it focuses on how to resume operations swiftly after a disaster.
  Example:
  A fire destroys the company's data center. The Disaster Recovery Plan is activated: IT restores all critical systems using offsite backups, activates cloud failover infrastructure, and reroutes user access to a secondary data center to resume operations.
### Redundant Site Considerations
Redundant Site:
Alternative sites for backup in case the primary location encounters a failure or interruption.
There are four types of categories based on your continuity locations:
1. Hot Site:
   A hot site is a fully equipped and fully operational backup facility that can immediately take over if the primary site fails or faces disruption.
   It includes all necessary hardware, software, network configurations, and up-to-date data.
   Cloud computing has made hot sites more accessible, but cloud alone does not replace every need - especially hardware-specific or regulated environments. Cloud-based hot sites are ideal for mission-critical systems because they offer very fast recovery times.
   
2. Warm Site:
   A warm site is partially equipped and can become fully operational within hours or days after a disruption. It usually contains essentials such as: power, basic networking, communication lines and some hardware or preconfigured systems
   It requires some setup before going live, so it offers a balance between cost and recovery speed.
   In many organizations, a hybrid DR model is used: critical staff go to a hot site and the rest of the workforce relocates to a warm or cold site.
   This ensures business continuity while keeping costs controlled.
   
3. Cold Side:
   A cold site is an empty facility that has power and physical space but no hardware, systems, or active infrastructure.
   Everything must be moved in or installed after a disaster occurs.
   It is the cheapest option, but it has the longest recovery time. 
   
4. Mobile Site:
   A mobile site uses portable units such as trailers, trucks, or modular structures that can be deployed anywhere.
   These units come with their own power, communication equipment, and sometimes even servers.
   The main benefit of a mobile recovery site is its self-sufficiency, making it ideal for emergencies where physical facilities are unavailable or damaged.

Choosing the appropriate recovery site—or combination of sites—is ultimately a decision made by senior management, based on the organization’s business needs, critical functions, risk tolerance, and potential disaster scenarios.

In addition to the four traditional types of redundant sites, a fifth option has recently emerged — the Virtual Site. A virtual site uses cloud-based environments to host critical systems and data, offering a highly flexible, scalable, and cost-effective approach to redundancy. Because cloud resources can be quickly provisioned, virtual sites allow organizations to restore operations rapidly without needing physical infrastructure.
- Virtual Hot Site:
  A fully replicated cloud environment where systems, applications, and data are continuously synchronized. It can take over operations instantly with little to no downtime.
- Virtual Warm Site:
  A partially replicated setup in the cloud. Some systems and data are preconfigured, while others need to be scaled up or activated during a disaster. It requires more time than a virtual hot site but is more cost-efficient.
- Virtual Cold Site:
  A minimal cloud environment with basic resources reserved. No active replication occurs, but infrastructure can be quickly provisioned when needed, keeping ongoing costs low while still enabling faster recovery than a physical cold site.

Things for consideration for redundant site:
 - Platform Diversity:
   Platform diversity is an important part of redundant site design. It involves using different platforms, systems, and infrastructure to reduce the risk of a single point of failure. By not relying on one technology stack, organizations improve their resilience during a disaster.
  
- Cloud-Provider Platform Diversity:
  This involves distributing resources across multiple cloud providers or multiple regions within a provider. Doing so minimizes the impact of a provider-wide outage or regional failure, ensuring continuity even if one cloud platform goes down.
  
- Broader Platform Diversity:
  Beyond cloud services, platform diversity also includes using different operating systems, hardware types, databases, or network setups across primary and backup sites. This avoids dependency on any single system that could fail unexpectedly.

When selecting a backup site, consider both the tech stack and employee workspace support
### Resilience and Recovery Testing
Resilience Testing:
Assesses the system's capacity to endure and adjust to disruptive occurrences. 
Recovery Testing:
Evaluates the system's ability to return to regular functioning following a disruptive incident.

Resilience and recovery testing serves as "fire drill" for enterprise networks and operations.
1. Tabletop Exercise:
   A tabletop exercise is a discussion-based simulation where teams walk through a hypothetical crisis without deploying any real resources. It strengthens coordination, builds team confidence, and helps identify weaknesses or gaps in the response plan before an actual incident occurs.

2. Failover Test:
   A failover test checks whether systems can smoothly transition to a backup environment - such as a hot site - without interrupting business operations. These tests are more resource -intensive and time-consuming but are critical to confirming that the organization’s failover plan will work during a real disaster.

3. Simulation:
   A simulation uses computer-generated or virtual models to mimic real-world disaster scenarios. This allows responders to practice technical actions in a controlled environment, testing decision-making and technical skills without impacting production systems.

4. Parallel Processing:
   Parallel processing involves running the primary system and a secondary backup system simultaneously with replicated data. This helps validate the stability, accuracy, and readiness of the backup environment before it is relied upon in an actual failover.

```
In resilience testing Tests ability to handle multiple failure scenarios 
In recovery testing Tests efficiency to recover from multiple failure points
```

Next module [[14. Security Architecture]]